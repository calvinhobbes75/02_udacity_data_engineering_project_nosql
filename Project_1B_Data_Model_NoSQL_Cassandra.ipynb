{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project: Data Modeling with Cassandra  \n",
    "A startup called Sparkify wants to analyze the data they've been collecting on songs and user activity on their new music streaming app. The analysis team is particularly interested in understanding what songs users are listening to. Currently, there is no easy way to query the data to generate the results, since the data reside in a directory of CSV files on user activity on the app.\n",
    "\n",
    "## Project Overview  \n",
    "In this project, data models are created with Apache Cassandra and ETL pipeline will be created using Python :  \n",
    "- keyspace and tables in Apache Cassandra are created to run queries.  \n",
    "- an ETL pipeline will transfer data from a set of CSV files within a directory to create a streamlined CSV file to model and insert data into Apache Cassandra tables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part I. ETL Pipeline for Pre-Processing the Files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import Python packages "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Python packages \n",
    "import pandas as pd\n",
    "import cassandra\n",
    "import re\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import json\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating list of filepaths to process original event csv data files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "/c/Users/sdelo/SynologyDrive/data_science/mooc/udacity/01_data_engineering/01_data_modeling/02_udacity_data_engineering_project_nosql\n"
    }
   ],
   "source": [
    "# checking your current working directory\n",
    "print(os.getcwd())\n",
    "\n",
    "# Get your current folder and subfolder event data\n",
    "filepath = os.getcwd() + '/event_data'\n",
    "\n",
    "# Create a for loop to create a list of files and collect each filepath\n",
    "for root, dirs, files in os.walk(filepath):\n",
    "    \n",
    "# join the file path and roots with the subdirectories using glob\n",
    "    file_path_list = glob.glob(os.path.join(root,'*'))\n",
    "    # print(file_path_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Processing the files to create the data file csv that will be used for Apache Casssandra tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": [
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "# initiating an empty list of rows that will be generated from each file\n",
    "full_data_rows_list = [] \n",
    "    \n",
    "# for every filepath in the file path list \n",
    "for f in file_path_list:\n",
    "\n",
    "# reading csv file \n",
    "    with open(f, 'r', encoding = 'utf8', newline='') as csvfile: \n",
    "        # creating a csv reader object \n",
    "        csvreader = csv.reader(csvfile) \n",
    "        next(csvreader)\n",
    "        \n",
    " # extracting each data row one by one and append it        \n",
    "        for line in csvreader:\n",
    "            #print(line)\n",
    "            full_data_rows_list.append(line) \n",
    "            \n",
    "# uncomment the code below if you would like to get total number of rows \n",
    "# print(len(full_data_rows_list))\n",
    "# uncomment the code below if you would like to check to see what the list of event data rows will look like\n",
    "# print(full_data_rows_list)\n",
    "\n",
    "# creating a smaller event data csv file called event_datafile_full csv that will be used to insert data into the \\\n",
    "# Apache Cassandra tables\n",
    "csv.register_dialect('myDialect', quoting=csv.QUOTE_ALL, skipinitialspace=True)\n",
    "\n",
    "with open('event_datafile_new.csv', 'w', encoding = 'utf8', newline='') as f:\n",
    "    writer = csv.writer(f, dialect='myDialect')\n",
    "    writer.writerow(['artist','firstName','gender','itemInSession','lastName','length',\\\n",
    "                'level','location','sessionId','song','userId'])\n",
    "    for row in full_data_rows_list:\n",
    "        if (row[0] == ''):\n",
    "            continue\n",
    "        writer.writerow((row[0], row[2], row[3], row[4], row[5], row[6], row[7], row[8], row[12], row[13], row[16]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "6821\n"
    }
   ],
   "source": [
    "# check the number of rows in your csv file\n",
    "with open('event_datafile_new.csv', 'r', encoding = 'utf8') as f:\n",
    "    print(sum(1 for line in f))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part II. Complete the Apache Cassandra coding portion of your project. \n",
    "\n",
    "## Now you are ready to work with the CSV file titled <font color=red>event_datafile_new.csv</font>, located within the Workspace directory.  The event_datafile_new.csv contains the following columns: \n",
    "- artist [0]\n",
    "- firstName of user [1]\n",
    "- gender of user [2]\n",
    "- item number in session [3]\n",
    "- last name of user [4]\n",
    "- length of the song [5]\n",
    "- level (paid or free song) [6]\n",
    "- location of the user [7]\n",
    "- sessionId [8]\n",
    "- song title [9]\n",
    "- userId [10]\n",
    "\n",
    "The image below is a screenshot of what the denormalized data should appear like in the <font color=red>**event_datafile_new.csv**</font> after the code above is run:<br>\n",
    "\n",
    "<img src=\"images/image_event_datafile_new.jpg\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pandas dataframe will be used offer easier features to process data instead of parsing raw CSV file\n",
    "# load denormalized event files to pandas dataframe df_events\n",
    "# this denormalized pandas dataframe df_events will be use to insert data to Cassandra table\n",
    "\n",
    "df_events = pd.read_csv('event_datafile_new.csv', encoding='utf8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 6820 entries, 0 to 6819\nData columns (total 11 columns):\n #   Column         Non-Null Count  Dtype  \n---  ------         --------------  -----  \n 0   artist         6820 non-null   object \n 1   firstName      6820 non-null   object \n 2   gender         6820 non-null   object \n 3   itemInSession  6820 non-null   int64  \n 4   lastName       6820 non-null   object \n 5   length         6820 non-null   float64\n 6   level          6820 non-null   object \n 7   location       6820 non-null   object \n 8   sessionId      6820 non-null   int64  \n 9   song           6820 non-null   object \n 10  userId         6820 non-null   int64  \ndtypes: float64(1), int64(3), object(7)\nmemory usage: 586.2+ KB\n"
    }
   ],
   "source": [
    "# view info and columns name of events data dataframe\n",
    "df_events.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "                        artist firstName gender  itemInSession  lastName  \\\n2849                    D.R.I.    Harper      M             16   Barrett   \n4007              Miami Horror      Lily      F             37      Koch   \n1423     Sunny Day Real Estate      Ryan      M              2     Smith   \n4487                Rick James     Kevin      M              1  Arellano   \n5826                       AFI     Wyatt      M              6     Scott   \n5802                   Nirvana     Tegan      F             59    Levine   \n4094               The Killers    Aleena      F             31     Kirby   \n5854                    Metric     Avery      F              1  Martinez   \n2511  Tony Bennett & k.d. lang   Kynnedi      F              0   Sanchez   \n6369             Reel Big Fish     Rylan      M             49    George   \n583             Heltah Skeltah    Aleena      F             67     Kirby   \n876                 Will Young      Kate      F             46   Harrell   \n2744             Amy Winehouse     Avery      F             78   Watkins   \n4852               Matt Redman    Sylvie      F              0      Cruz   \n4412                      MGMT      Lily      F              5      Koch   \n4679             Abstract Rude      Lily      F             57      Koch   \n4206                   Orishas     Chloe      F             50    Cuevas   \n3878                 Tom Petty    Jayden      M              9    Graves   \n3169                       M83   Kinsley      F             27     Young   \n6035              Eric Clapton     Layla      F              9   Griffin   \n\n         length level                                      location  \\\n2849   66.61179  paid         New York-Newark-Jersey City, NY-NJ-PA   \n4007  386.50730  paid            Chicago-Naperville-Elgin, IL-IN-WI   \n1423  198.97424  free            San Jose-Sunnyvale-Santa Clara, CA   \n4487  263.60118  free                       Harrisburg-Carlisle, PA   \n5826  256.86159  free                     Eureka-Arcata-Fortuna, CA   \n5802  257.01832  paid                   Portland-South Portland, ME   \n4094  220.89098  paid                      Waterloo-Cedar Falls, IA   \n5854  171.25832  paid             Atlanta-Sandy Springs-Roswell, GA   \n2511  188.26404  free                              Cedar Rapids, IA   \n6369  185.80853  paid                         Birmingham-Hoover, AL   \n583   165.64200  paid                      Waterloo-Cedar Falls, IA   \n876   213.55057  paid                      Lansing-East Lansing, MI   \n2744  164.85832  paid            San Jose-Sunnyvale-Santa Clara, CA   \n4852  303.46404  free  Washington-Arlington-Alexandria, DC-VA-MD-WV   \n4412  264.17587  paid            Chicago-Naperville-Elgin, IL-IN-WI   \n4679  196.85832  paid            Chicago-Naperville-Elgin, IL-IN-WI   \n4206  247.43138  paid             San Francisco-Oakland-Hayward, CA   \n3878  263.23546  paid                              Marinette, WI-MI   \n3169  391.54893  paid                                 Red Bluff, CA   \n6035  279.95383  paid                  Lake Havasu City-Kingman, AZ   \n\n      sessionId                                  song  userId  \n2849        404  Stupid_ Stupid War (Dealing With It)      42  \n4007        716        Sometimes (Hook N Sling Remix)      15  \n1423        431                          Red Elephant      26  \n4487        714                           Ghetto Life      66  \n5826        922                         The Interview       9  \n5802        992                               Lithium      80  \n4094        639                   When You Were Young      44  \n5854        140                        Gimme Sympathy      82  \n2511        334                        That's My Home      89  \n6369        983              She Has A Girlfriend Now      16  \n583         269                Place To Be (Explicit)      44  \n876         293                       Leave Right Now      97  \n2744        324                  He Can Only Hold Her      30  \n4852        864                  Blessed Be Your Name      10  \n4412        764                       Time To Pretend      15  \n4679        818                             Nuff Fire      15  \n4206        758                         Quien Te Dijo      49  \n3878        594                  Runnin' Down A Dream      25  \n3169        436                             Carresses      85  \n6035        984                                 Smile      24  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>artist</th>\n      <th>firstName</th>\n      <th>gender</th>\n      <th>itemInSession</th>\n      <th>lastName</th>\n      <th>length</th>\n      <th>level</th>\n      <th>location</th>\n      <th>sessionId</th>\n      <th>song</th>\n      <th>userId</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2849</th>\n      <td>D.R.I.</td>\n      <td>Harper</td>\n      <td>M</td>\n      <td>16</td>\n      <td>Barrett</td>\n      <td>66.61179</td>\n      <td>paid</td>\n      <td>New York-Newark-Jersey City, NY-NJ-PA</td>\n      <td>404</td>\n      <td>Stupid_ Stupid War (Dealing With It)</td>\n      <td>42</td>\n    </tr>\n    <tr>\n      <th>4007</th>\n      <td>Miami Horror</td>\n      <td>Lily</td>\n      <td>F</td>\n      <td>37</td>\n      <td>Koch</td>\n      <td>386.50730</td>\n      <td>paid</td>\n      <td>Chicago-Naperville-Elgin, IL-IN-WI</td>\n      <td>716</td>\n      <td>Sometimes (Hook N Sling Remix)</td>\n      <td>15</td>\n    </tr>\n    <tr>\n      <th>1423</th>\n      <td>Sunny Day Real Estate</td>\n      <td>Ryan</td>\n      <td>M</td>\n      <td>2</td>\n      <td>Smith</td>\n      <td>198.97424</td>\n      <td>free</td>\n      <td>San Jose-Sunnyvale-Santa Clara, CA</td>\n      <td>431</td>\n      <td>Red Elephant</td>\n      <td>26</td>\n    </tr>\n    <tr>\n      <th>4487</th>\n      <td>Rick James</td>\n      <td>Kevin</td>\n      <td>M</td>\n      <td>1</td>\n      <td>Arellano</td>\n      <td>263.60118</td>\n      <td>free</td>\n      <td>Harrisburg-Carlisle, PA</td>\n      <td>714</td>\n      <td>Ghetto Life</td>\n      <td>66</td>\n    </tr>\n    <tr>\n      <th>5826</th>\n      <td>AFI</td>\n      <td>Wyatt</td>\n      <td>M</td>\n      <td>6</td>\n      <td>Scott</td>\n      <td>256.86159</td>\n      <td>free</td>\n      <td>Eureka-Arcata-Fortuna, CA</td>\n      <td>922</td>\n      <td>The Interview</td>\n      <td>9</td>\n    </tr>\n    <tr>\n      <th>5802</th>\n      <td>Nirvana</td>\n      <td>Tegan</td>\n      <td>F</td>\n      <td>59</td>\n      <td>Levine</td>\n      <td>257.01832</td>\n      <td>paid</td>\n      <td>Portland-South Portland, ME</td>\n      <td>992</td>\n      <td>Lithium</td>\n      <td>80</td>\n    </tr>\n    <tr>\n      <th>4094</th>\n      <td>The Killers</td>\n      <td>Aleena</td>\n      <td>F</td>\n      <td>31</td>\n      <td>Kirby</td>\n      <td>220.89098</td>\n      <td>paid</td>\n      <td>Waterloo-Cedar Falls, IA</td>\n      <td>639</td>\n      <td>When You Were Young</td>\n      <td>44</td>\n    </tr>\n    <tr>\n      <th>5854</th>\n      <td>Metric</td>\n      <td>Avery</td>\n      <td>F</td>\n      <td>1</td>\n      <td>Martinez</td>\n      <td>171.25832</td>\n      <td>paid</td>\n      <td>Atlanta-Sandy Springs-Roswell, GA</td>\n      <td>140</td>\n      <td>Gimme Sympathy</td>\n      <td>82</td>\n    </tr>\n    <tr>\n      <th>2511</th>\n      <td>Tony Bennett &amp; k.d. lang</td>\n      <td>Kynnedi</td>\n      <td>F</td>\n      <td>0</td>\n      <td>Sanchez</td>\n      <td>188.26404</td>\n      <td>free</td>\n      <td>Cedar Rapids, IA</td>\n      <td>334</td>\n      <td>That's My Home</td>\n      <td>89</td>\n    </tr>\n    <tr>\n      <th>6369</th>\n      <td>Reel Big Fish</td>\n      <td>Rylan</td>\n      <td>M</td>\n      <td>49</td>\n      <td>George</td>\n      <td>185.80853</td>\n      <td>paid</td>\n      <td>Birmingham-Hoover, AL</td>\n      <td>983</td>\n      <td>She Has A Girlfriend Now</td>\n      <td>16</td>\n    </tr>\n    <tr>\n      <th>583</th>\n      <td>Heltah Skeltah</td>\n      <td>Aleena</td>\n      <td>F</td>\n      <td>67</td>\n      <td>Kirby</td>\n      <td>165.64200</td>\n      <td>paid</td>\n      <td>Waterloo-Cedar Falls, IA</td>\n      <td>269</td>\n      <td>Place To Be (Explicit)</td>\n      <td>44</td>\n    </tr>\n    <tr>\n      <th>876</th>\n      <td>Will Young</td>\n      <td>Kate</td>\n      <td>F</td>\n      <td>46</td>\n      <td>Harrell</td>\n      <td>213.55057</td>\n      <td>paid</td>\n      <td>Lansing-East Lansing, MI</td>\n      <td>293</td>\n      <td>Leave Right Now</td>\n      <td>97</td>\n    </tr>\n    <tr>\n      <th>2744</th>\n      <td>Amy Winehouse</td>\n      <td>Avery</td>\n      <td>F</td>\n      <td>78</td>\n      <td>Watkins</td>\n      <td>164.85832</td>\n      <td>paid</td>\n      <td>San Jose-Sunnyvale-Santa Clara, CA</td>\n      <td>324</td>\n      <td>He Can Only Hold Her</td>\n      <td>30</td>\n    </tr>\n    <tr>\n      <th>4852</th>\n      <td>Matt Redman</td>\n      <td>Sylvie</td>\n      <td>F</td>\n      <td>0</td>\n      <td>Cruz</td>\n      <td>303.46404</td>\n      <td>free</td>\n      <td>Washington-Arlington-Alexandria, DC-VA-MD-WV</td>\n      <td>864</td>\n      <td>Blessed Be Your Name</td>\n      <td>10</td>\n    </tr>\n    <tr>\n      <th>4412</th>\n      <td>MGMT</td>\n      <td>Lily</td>\n      <td>F</td>\n      <td>5</td>\n      <td>Koch</td>\n      <td>264.17587</td>\n      <td>paid</td>\n      <td>Chicago-Naperville-Elgin, IL-IN-WI</td>\n      <td>764</td>\n      <td>Time To Pretend</td>\n      <td>15</td>\n    </tr>\n    <tr>\n      <th>4679</th>\n      <td>Abstract Rude</td>\n      <td>Lily</td>\n      <td>F</td>\n      <td>57</td>\n      <td>Koch</td>\n      <td>196.85832</td>\n      <td>paid</td>\n      <td>Chicago-Naperville-Elgin, IL-IN-WI</td>\n      <td>818</td>\n      <td>Nuff Fire</td>\n      <td>15</td>\n    </tr>\n    <tr>\n      <th>4206</th>\n      <td>Orishas</td>\n      <td>Chloe</td>\n      <td>F</td>\n      <td>50</td>\n      <td>Cuevas</td>\n      <td>247.43138</td>\n      <td>paid</td>\n      <td>San Francisco-Oakland-Hayward, CA</td>\n      <td>758</td>\n      <td>Quien Te Dijo</td>\n      <td>49</td>\n    </tr>\n    <tr>\n      <th>3878</th>\n      <td>Tom Petty</td>\n      <td>Jayden</td>\n      <td>M</td>\n      <td>9</td>\n      <td>Graves</td>\n      <td>263.23546</td>\n      <td>paid</td>\n      <td>Marinette, WI-MI</td>\n      <td>594</td>\n      <td>Runnin' Down A Dream</td>\n      <td>25</td>\n    </tr>\n    <tr>\n      <th>3169</th>\n      <td>M83</td>\n      <td>Kinsley</td>\n      <td>F</td>\n      <td>27</td>\n      <td>Young</td>\n      <td>391.54893</td>\n      <td>paid</td>\n      <td>Red Bluff, CA</td>\n      <td>436</td>\n      <td>Carresses</td>\n      <td>85</td>\n    </tr>\n    <tr>\n      <th>6035</th>\n      <td>Eric Clapton</td>\n      <td>Layla</td>\n      <td>F</td>\n      <td>9</td>\n      <td>Griffin</td>\n      <td>279.95383</td>\n      <td>paid</td>\n      <td>Lake Havasu City-Kingman, AZ</td>\n      <td>984</td>\n      <td>Smile</td>\n      <td>24</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "# view random sampling of events data to understand better the denormalized event dataset\n",
    "df_events.sample(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ETL pipeline to create Cassandra Cluster, Keyspace, tables, queries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ypu must run a local Cassandra cluster with Docker before running the cells below on a local computer :\n",
    "``` Docker\n",
    "docker-compose up -d\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating a Cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This will make a connection to a Cassandra instance your local machine \n",
    "# (127.0.0.1)\n",
    "\n",
    "from cassandra.cluster import Cluster\n",
    "\n",
    "\n",
    "# To establish connection and begin executing queries, connect session to Cassandra local cluster (Docker)\n",
    "try:\n",
    "    cluster = Cluster(['127.0.0.1'])\n",
    "    session = cluster.connect()\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Keyspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Keyspace called sparkify\n",
    "try:\n",
    "    session.execute(\"\"\"\n",
    "    CREATE KEYSPACE IF NOT EXISTS sparkify \n",
    "    WITH REPLICATION = \n",
    "    { 'class' : 'SimpleStrategy', 'replication_factor' : 1 }\"\"\"\n",
    ")\n",
    "\n",
    "except Exception as e:\n",
    "    print(e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set KEYSPACE to the keyspace sparkify above\n",
    "try:\n",
    "    session.set_keyspace('sparkify')\n",
    "except Exception as e:\n",
    "    print(e)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop any existing tables before creating them\n",
    "\n",
    "We need to answer 3 queries so there will be 3 data models. 3 tables will be created "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use if necessary the following DROP TABLE queries to delete and reset existing tables before testing the ETL pipeline\n",
    "\n",
    "drop_table_query_1 = \"DROP TABLE IF EXISTS session_details;\"\n",
    "session.execute(drop_table_query_1)\n",
    "\n",
    "drop_table_query_2 = \"DROP TABLE IF EXISTS user_activity_in_session;\"\n",
    "session.execute(drop_table_query_2)\n",
    "\n",
    "drop_table_query_3 = \"DROP TABLE IF EXISTS songs_listeners;\"\n",
    "session.execute(drop_table_query_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now we need to create tables to run the following queries. Remember, with Apache Cassandra you model the database tables on the queries you want to run."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Creating queries to ask the following three questions from the event data\n",
    "\n",
    "### 1. Give me the artist, song title and song's length in the music app history that was heard during  sessionId = 338, and itemInSession  = 4\n",
    "\n",
    "\n",
    "### 2. Give me only the following: name of artist, song (sorted by itemInSession) and user (first and last name) for userid = 10, sessionid = 182\n",
    "    \n",
    "\n",
    "### 3. Give me every user name (first and last) in my music app history who listened to the song 'All Hands Against His Own'\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating and testing Data Model for the following query\n",
    "### 1. Give me the artist, song title and song's length in the music app history that was heard during sessionId = 338, and itemInSession = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Data Model for Cassandra Database to ansnwer the query\n",
    "#\n",
    "# the query is looking for artist and song information for specific sessionId and itemInSession\n",
    "# sessionId and itemInSession can be used as primary key\n",
    "# here is the corresponding CREATE TABLE query -> create session_details table\n",
    "\n",
    "create_table_query_1 = \"CREATE TABLE IF NOT EXISTS session_details \"\n",
    "create_table_query_1 = create_table_query_1 + \"(session_id int, item_in_session int, artist_name text, song_title text, song_length float, PRIMARY KEY (session_id, item_in_session))\"\n",
    "try:\n",
    "    session.execute(create_table_query_1)\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load event data pandas dataframe to cassandra table using PreparedStatements \n",
    "# here is the INSERT INTO query to load the data to Cassandra database to session_details table\n",
    "\n",
    "insert_query_1 = \"INSERT INTO session_details (session_id, item_in_session, artist_name, song_title, song_length)\"\n",
    "insert_query_1 = insert_query_1 + \" VALUES (?, ?, ?, ?, ?)\"\n",
    "\n",
    "prepared_query_1 = session.prepare(insert_query_1)\n",
    "\n",
    "for index, row in df_events.iterrows():\n",
    "    session.execute(prepared_query_1, (row['sessionId'], row['itemInSession'], row['artist'],\n",
    "                                        row['song'], row['length']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "  artist_name                       song_title  song_length\n0   Faithless  Music Matters (Mark Knight Dub)   495.307312",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>artist_name</th>\n      <th>song_title</th>\n      <th>song_length</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Faithless</td>\n      <td>Music Matters (Mark Knight Dub)</td>\n      <td>495.307312</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "## Here is the SELECT statement to verify the data was entered into the table\n",
    "## Query 1:  Give me the artist, song title and song's length in the music app history that was heard during \\\n",
    "## sessionId = 338, and itemInSession = 4\n",
    "\n",
    "sessionId = 338\n",
    "itemInSession = 4\n",
    "\n",
    "select_query_1 = \"SELECT artist_name, song_title, song_length \\\n",
    "                    FROM session_details \\\n",
    "                    WHERE session_id = %s \\\n",
    "                    AND item_in_session = %s\"\n",
    "\n",
    "# the select query is executed and results are returned to a pandas dataframe\n",
    "\n",
    "rows = session.execute(select_query_1, (sessionId, itemInSession))\n",
    "\n",
    "# define a results dictionnary\n",
    "query_results_1 = {'artist_name':[],\n",
    "                    'song_title':[],\n",
    "                    'song_length' :[]\n",
    "                    }\n",
    "\n",
    "# append the results row by row to the dictionnary\n",
    "for row in rows:\n",
    "    query_results_1['artist_name'].append(row.artist_name)     \n",
    "    query_results_1['song_title'].append(row.song_title)\n",
    "    query_results_1['song_length'].append(row.song_length)\n",
    "\n",
    "# create a pandas dataframe from the query results\n",
    "df_query_1 = pd.DataFrame(query_results_1)\n",
    "\n",
    "# view query results dataframe\n",
    "df_query_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating and testing Data Model for the following query\n",
    "### 2. Give me only the following: name of artist, song (sorted by itemInSession) and user (first and last name) for userid = 10, sessionid = 182"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Data Model for Cassandra Database to ansnwer the query\n",
    "#\n",
    "# the query is looking for specific userid and sessionid\n",
    "# (userid, sessionid) can be used as primary key\n",
    "# we will add itemInSession  as clustering Columns to sort the data \n",
    "# here is the corresponding CREATE TABLE query -> create user_activity_in_session table\n",
    "\n",
    "create_table_query_2 = \"CREATE TABLE IF NOT EXISTS user_activity_in_session \"\n",
    "create_table_query_2 = create_table_query_2 + \"(user_id int, session_id int, item_in_session int, artist_name text, song_title text, user_firstname text, user_lastname text, PRIMARY KEY ((user_id, session_id), item_in_session))\"\n",
    "try:\n",
    "    session.execute(create_table_query_2)\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load event data pandas dataframe to cassandra table using PreparedStatements \n",
    "# here is the INSERT INTO query to load the data to Cassandra database to user_activity_in_session table\n",
    "\n",
    "\n",
    "insert_query_2 = \"INSERT INTO user_activity_in_session (user_id, session_id, item_in_session, artist_name, song_title, user_firstname, user_lastname)\"\n",
    "insert_query_2 = insert_query_2 + \" VALUES (?, ?, ?, ?, ?, ?, ?)\"\n",
    "\n",
    "prepared_query_2 = session.prepare(insert_query_2)\n",
    "\n",
    "for index, row in df_events.iterrows():\n",
    "    session.execute(prepared_query_2, (row['userId'], row['sessionId'], row['itemInSession'],\n",
    "                                        row['artist'], row['song'], row['firstName'], row['lastName']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "         artist_name                                         song_title  \\\n0   Down To The Bone                                 Keep On Keepin' On   \n1       Three Drives                                        Greece 2000   \n2  Sebastien Tellier                                          Kilometer   \n3      Lonnie Gordon  Catch You Baby (Steve Pitron & Max Sanna Radio...   \n\n  user_firstname user_lastname  \n0         Sylvie          Cruz  \n1         Sylvie          Cruz  \n2         Sylvie          Cruz  \n3         Sylvie          Cruz  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>artist_name</th>\n      <th>song_title</th>\n      <th>user_firstname</th>\n      <th>user_lastname</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Down To The Bone</td>\n      <td>Keep On Keepin' On</td>\n      <td>Sylvie</td>\n      <td>Cruz</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Three Drives</td>\n      <td>Greece 2000</td>\n      <td>Sylvie</td>\n      <td>Cruz</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Sebastien Tellier</td>\n      <td>Kilometer</td>\n      <td>Sylvie</td>\n      <td>Cruz</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Lonnie Gordon</td>\n      <td>Catch You Baby (Steve Pitron &amp; Max Sanna Radio...</td>\n      <td>Sylvie</td>\n      <td>Cruz</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "source": [
    "## Here is the SELECT statement to verify the data was entered into the table\n",
    "## Query 2:  Give me only the following: name of artist, song (sorted by itemInSession) and user (first and last name) \\\n",
    "## for userid = 10, sessionid = 182\n",
    "\n",
    "userId = 10\n",
    "sessionId = 182\n",
    "\n",
    "select_query_2 = \"SELECT artist_name, song_title, user_firstname, user_lastname \\\n",
    "                    FROM user_activity_in_session \\\n",
    "                    WHERE user_id = %s \\\n",
    "                    AND session_id = %s\"\n",
    "\n",
    "# the select query is executed and results are returned to a pandas dataframe\n",
    "rows = session.execute(select_query_2, (userId, sessionId))\n",
    "\n",
    "# define a results dictionnary\n",
    "query_results_2 = {'artist_name':[],\n",
    "                'song_title' :[],\n",
    "                'user_firstname' :[],\n",
    "                'user_lastname' : []\n",
    "                }\n",
    "\n",
    "# append the results row by row to the dictionnary\n",
    "for row in rows:   \n",
    "    query_results_2['artist_name'].append(row.artist_name)\n",
    "    query_results_2['song_title'].append(row.song_title)\n",
    "    query_results_2['user_firstname'].append(row.user_firstname)\n",
    "    query_results_2['user_lastname'].append(row.user_lastname)\n",
    "\n",
    "# create a pandas dataframe from the query results\n",
    "df_query_2 = pd.DataFrame(query_results_2)\n",
    "\n",
    "# view query results dataframe and check that songs are sorted by item_in_session\n",
    "df_query_2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating and testing Data Model for the following query\n",
    "### 3. Give me every user name (first and last) in my music app history who listened to the song 'All Hands Against His Own'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Data Model for Cassandra Database to ansnwer the query\n",
    "#\n",
    "# the query is looking for specific song and users listener\n",
    "# song and userid can be used as primary key\n",
    "# here is the corresponding CREATE TABLE query -> create songs_listeners table\n",
    "\n",
    "create_table_query_3 = \"CREATE TABLE IF NOT EXISTS songs_listeners \"\n",
    "create_table_query_3 = create_table_query_3 + \"(song_title text, user_id int, user_firstname text, user_lastname text, PRIMARY KEY (song_title, user_id))\"\n",
    "try:\n",
    "    session.execute(create_table_query_3)\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load event data pandas dataframe to cassandra table using PreparedStatements \n",
    "# here is the INSERT INTO query to load the data to Cassandra database to songs_listeners table\n",
    "\n",
    "insert_query_3 = \"INSERT INTO songs_listeners (song_title, user_id, user_firstname, user_lastname)\"\n",
    "insert_query_3 = insert_query_3 + \" VALUES ( ?, ?, ?, ?)\"\n",
    "\n",
    "prepared = session.prepare(insert_query_3)\n",
    "\n",
    "for index, row in df_events.iterrows():\n",
    "    session.execute(prepared, (row['song'], row['userId'], row['firstName'], row['lastName']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "  user_firstname user_lastname\n0     Jacqueline         Lynch\n1          Tegan        Levine\n2           Sara       Johnson",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>user_firstname</th>\n      <th>user_lastname</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Jacqueline</td>\n      <td>Lynch</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Tegan</td>\n      <td>Levine</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Sara</td>\n      <td>Johnson</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 19
    }
   ],
   "source": [
    "## Here is the SELECT statement to verify the data was entered into the table\n",
    "# Query 3: Give me every user name (first and last) in my music app history who listened to the song 'All Hands Against His Own'\n",
    "\n",
    "song = 'All Hands Against His Own'\n",
    "\n",
    "select_query_3 = \"SELECT user_id, user_firstname, user_lastname \\\n",
    "                    FROM songs_listeners \\\n",
    "                    WHERE song_title = %s\"\n",
    "\n",
    "# the select query is executed and results are returned to a pandas dataframe\n",
    "rows = session.execute(select_query_3, (song,))\n",
    "\n",
    "# define a results dictionnary\n",
    "query_results_3 = {\"user_firstname\":[],\n",
    "                \"user_lastname\" : []\n",
    "            }\n",
    "\n",
    "# append the results row by row to the dictionnary\n",
    "for row in rows:  \n",
    "    query_results_3['user_firstname'].append(row.user_firstname)\n",
    "    query_results_3['user_lastname'].append(row.user_lastname)\n",
    "\n",
    "# create a pandas dataframe from the query results\n",
    "df_query_3 = pd.DataFrame(query_results_3)\n",
    "\n",
    "\n",
    "# view query results dataframe and check that user_id is correct fot the users\n",
    "df_query_3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop the tables before closing out the sessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "<cassandra.cluster.ResultSet at 0x7f3c884189d0>"
     },
     "metadata": {},
     "execution_count": 20
    }
   ],
   "source": [
    "drop_table_query_1 = \"DROP TABLE IF EXISTS session_details;\"\n",
    "session.execute(drop_table_query_1)\n",
    "\n",
    "drop_table_query_2 = \"DROP TABLE IF EXISTS user_activity_in_session;\"\n",
    "session.execute(drop_table_query_2)\n",
    "\n",
    "drop_table_query_3 = \"DROP TABLE IF EXISTS songs_listeners;\"\n",
    "session.execute(drop_table_query_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Close the session and cluster connectionÂ¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "session.shutdown()\n",
    "cluster.shutdown()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.7 64-bit ('udacity2': conda)",
   "language": "python",
   "name": "python37764bitudacity2conda37dcb3d9d79a4aebb4d3a98a5ea1998d"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}